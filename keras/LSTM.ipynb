{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7HDQ6TDKr3s"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1BCglf7LVqE"
   },
   "outputs": [],
   "source": [
    "max_features = 40000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 500\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below does following things:\n",
    "# 1)It downloads the data\n",
    "# 2)It downloads the first 20000 top words for each review\n",
    "# 3)It splits the data into a test and a training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "rAPDuXezLZP6",
    "outputId": "af69943f-38f8-400f-9dd8-b50cdc5ed566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...\n",
       "1  [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...\n",
       "2  [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...\n",
       "3  [1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 1...\n",
       "4  [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "pd.DataFrame(x_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7mbJ7_-Ve9B"
   },
   "outputs": [],
   "source": [
    "# We want to trim each review to its first 500 words. \n",
    "# We need to have text samples of the same length before we feed them to the network. \n",
    "# If reviews are shorter than 500 words we will pad them with 0.\n",
    "# Keras offers a super easy function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "dTSS5HbQLd8i",
    "outputId": "43978aae-7ca6-4c74-96c9-95ef1fb2247d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 500)\n",
      "x_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iqCdq0zLLg9C",
    "outputId": "23ada3a4-40c2-40c4-ef8a-fc0b0e4ca57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 500))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "p-F-AQ0LLpvr",
    "outputId": "9b1f6789-ce5a-495d-c265-59632c125120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 703s 28ms/step - loss: 0.4611 - acc: 0.7854 - val_loss: 0.3673 - val_acc: 0.8459\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 702s 28ms/step - loss: 0.2396 - acc: 0.9100 - val_loss: 0.3612 - val_acc: 0.8570\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 703s 28ms/step - loss: 0.1347 - acc: 0.9534 - val_loss: 0.4489 - val_acc: 0.8361\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 702s 28ms/step - loss: 0.0790 - acc: 0.9742 - val_loss: 0.4727 - val_acc: 0.8518\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 703s 28ms/step - loss: 0.0452 - acc: 0.9863 - val_loss: 0.5665 - val_acc: 0.8420\n",
      "25000/25000 [==============================] - 162s 6ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 500)         20000000  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 250)         125250    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 20,265,751\n",
      "Trainable params: 20,265,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test score: 0.5664715587806701\n",
      "Test accuracy: 0.8419599999809265\n"
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print(model.summary())\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YliVdXBvVj0n",
    "outputId": "cb788e06-c948-4dce-f3eb-bd4a72ee100d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked the movie it was fun. Sentiment: 0.6240958\n",
      "worst movie ever. Sentiment: 0.82107025\n"
     ]
    }
   ],
   "source": [
    "#predict sentiment from reviews\n",
    "word_to_id = imdb.get_word_index()\n",
    "bad = \"worst movie ever\"\n",
    "good = \"i liked the movie it was fun\"\n",
    "for review in [good,bad]:\n",
    "    tmp = []\n",
    "    for word in review.split(\" \"):\n",
    "        tmp.append(word_to_id[word])\n",
    "    tmp_padded = sequence.pad_sequences([tmp], maxlen=maxlen) \n",
    "    print(\"%s. Sentiment: %s\" % (review,model.predict(([tmp_padded][0]))[0][0]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled9.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
